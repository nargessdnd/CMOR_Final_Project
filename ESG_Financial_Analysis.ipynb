{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESG and Financial Performance Analysis\n",
    "\n",
    "This notebook analyzes the relationship between ESG (Environmental, Social, and Governance) scores and financial performance metrics using the \"ESG and Financial Performance\" dataset. We will explore, preprocess, visualize the data, and then apply various supervised and unsupervised machine learning algorithms implemented in the `Supervised_Learning` and `Unsupervised_Learning` directories.\n",
    "\n",
    "## Contents:\n",
    "1.  **Data Loading and Initial Exploration:** Load the dataset and perform basic checks (shape, info, missing values, summary statistics).\n",
    "2.  **Data Preprocessing and Cleaning:** Handle missing values, encode categorical features, and scale numerical features using the provided utility function.\n",
    "3.  **Exploratory Data Visualization:** Visualize data distributions and correlations.\n",
    "4.  **Data Preparation for Machine Learning:** Split data into features (X) and target (y) for regression and classification tasks, and perform train/test splits.\n",
    "5.  **Supervised Learning:**\n",
    "    * Regression Task (Predicting ProfitMargin)\n",
    "        * Linear Regression\n",
    "        * Decision Tree Regressor\n",
    "        * K-Nearest Neighbors (KNN) Regressor\n",
    "        * Random Forest Regressor\n",
    "        * Neural Network (Regression)\n",
    "        * Gradient Boosting Regressor\n",
    "        * Regression Model Comparison\n",
    "    * Classification Task (Predicting High/Low ESG_Overall)\n",
    "        * Perceptron\n",
    "        * Logistic Regression\n",
    "        * K-Nearest Neighbors (KNN) Classifier\n",
    "        * Decision Tree Classifier\n",
    "        * Random Forest Classifier\n",
    "        * Neural Network (Classification)\n",
    "        * AdaBoost Classifier\n",
    "        * Classification Model Comparison\n",
    "6.  **Unsupervised Learning:**\n",
    "    * Principal Component Analysis (PCA)\n",
    "    * K-Means Clustering\n",
    "    * DBSCAN Clustering\n",
    "    * Clustering Model Comparison\n",
    "    * Singular Value Decomposition (SVD) for Compression (Demonstration)\n",
    "7.  **Conclusion:** Summarize findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, r2_score, \n",
    "    accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, \n",
    "    silhouette_score\n",
    ")\n",
    "from sklearn.decomposition import PCA as SklearnPCA # For comparison/visualization\n",
    "from sklearn.cluster import DBSCAN as SklearnDBSCAN # For comparison/visualization\n",
    "from PIL import Image # For SVD section example\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# Import custom utilities and algorithms\n",
    "from utils.data_preprocessing import preprocess_esg_data, create_feature_target_split\n",
    "from utils.data_visualization import (\n",
    "    plot_esg_distributions,\n",
    "    plot_correlation_matrix,\n",
    "    plot_financial_metrics,\n",
    "    plot_esg_vs_financial,\n",
    "    plot_pca_results,\n",
    "    plot_clusters,\n",
    "    plot_regression_results,\n",
    "    plot_classification_results,\n",
    "    plot_model_comparison # Added for comparing models\n",
    ")\n",
    "\n",
    "# Supervised Learning Algorithms\n",
    "from Supervised_Learning.perceptron import Perceptron\n",
    "from Supervised_Learning.linear_regression import LinearRegression\n",
    "from Supervised_Learning.logistic_regression import LogisticRegression\n",
    "from Supervised_Learning.neural_network import NeuralNetwork\n",
    "from Supervised_Learning.knn import KNNClassifier, KNNRegressor\n",
    "from Supervised_Learning.decision_tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from Supervised_Learning.random_forest import RandomForestClassifier, RandomForestRegressor\n",
    "from Supervised_Learning.ensemble_methods import AdaBoostClassifier, GradientBoostingRegressor\n",
    "\n",
    "# Unsupervised Learning Algorithms\n",
    "from Unsupervised_Learning.kmeans import KMeans\n",
    "from Unsupervised_Learning.dbscan import DBSCAN\n",
    "from Unsupervised_Learning.pca import PCA\n",
    "from Unsupervised_Learning.svd_compression import SVDCompression\n",
    "\n",
    "# Set visualization style\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "print(\"Libraries and modules imported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the relative path to the data file\n",
    "# Assumes the notebook is running in the root directory 'ML_Course_Project'\n",
    "file_path = \"./data/company_esg_financial_dataset.csv\"\n",
    "\n",
    "df_original = None # Initialize df to None\n",
    "\n",
    "try:\n",
    "    # Check if the file exists at the specified path\n",
    "    if os.path.exists(file_path):\n",
    "        # Load the CSV file into a pandas DataFrame\n",
    "        df_original = pd.read_csv(file_path)\n",
    "        print(f\"Successfully loaded data from: {file_path}\")\n",
    "    else:\n",
    "        print(f\"Error: File not found at the specified path: {file_path}\")\n",
    "        print(\"Please ensure the 'data' directory exists and the file 'company_esg_financial_dataset.csv' is inside it.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found at path: {file_path}\")\n",
    "    print(\"Please double-check the path and file name.\")\n",
    "except pd.errors.EmptyDataError:\n",
    "    print(f\"Error: The file at {file_path} is empty.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading the file: {e}\")\n",
    "\n",
    "# Proceed with analysis if the DataFrame was loaded successfully\n",
    "if df_original is not None:\n",
    "    print(f\"\\nDataset loaded successfully.\")\n",
    "    print(f\"Shape of the DataFrame: {df_original.shape}\")\n",
    "    print(\"\\nFirst 5 records:\")\n",
    "    display(df_original.head())\n",
    "else:\n",
    "    print(\"\\nFailed to load dataset. Please check the file path and integrity.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get basic information about the dataset\n",
    "if df_original is not None:\n",
    "    print(\"\\nDataset Information:\")\n",
    "    df_original.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "if df_original is not None:\n",
    "    missing_values = df_original.isnull().sum()\n",
    "    missing_percentage = (missing_values / len(df_original)) * 100\n",
    "    missing_df = pd.DataFrame({\n",
    "        'Missing Values': missing_values,\n",
    "        'Percentage': missing_percentage\n",
    "    })\n",
    "    print(\"\\nMissing Values Analysis:\")\n",
    "    display(missing_df[missing_df['Missing Values'] > 0].sort_values('Missing Values', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Observation:* The `GrowthRate` column has 1000 missing values (9.1%). All other columns are complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics of numerical columns\n",
    "if df_original is not None:\n",
    "    print(\"\\nSummary Statistics:\")\n",
    "    display(df_original.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique values in categorical columns\n",
    "if df_original is not None:\n",
    "    categorical_cols = df_original.select_dtypes(include=['object']).columns\n",
    "    print(\"\\nUnique values in categorical columns:\")\n",
    "    for col in categorical_cols:\n",
    "        print(f\"--- {col} ({df_original[col].nunique()} unique) ---\")\n",
    "        if df_original[col].nunique() < 15:\n",
    "             print(df_original[col].value_counts())\n",
    "        else:\n",
    "             print(f\"(Too many unique values to display: {df_original[col].nunique()})\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing and Cleaning\n",
    "\n",
    "We will use the `preprocess_esg_data` function from `utils.data_preprocessing`. This function handles:\n",
    "1.  **Missing Value Imputation:** Uses median for numerical features (`GrowthRate`) and mode for categorical features (though none are missing here).\n",
    "2.  **Categorical Encoding:** Converts `Industry` and `Region` into numerical representations using Label Encoding.\n",
    "3.  **Feature Scaling:** Standardizes numerical features to have zero mean and unit variance using `StandardScaler`.\n",
    "4.  **Outlier Handling (Optional in function):** The provided utility function includes an optional IQR-based outlier handling step, which we will use here for robustness, although the impact might be minimal depending on the algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_original is not None:\n",
    "    # Apply preprocessing\n",
    "    # Note: We drop CompanyID and CompanyName as they are identifiers and not typically used as features\n",
    "    df_processed = preprocess_esg_data(df_original.drop(columns=['CompanyID', 'CompanyName']))\n",
    "    \n",
    "    print(\"Dataset shape after preprocessing:\", df_processed.shape)\n",
    "    print(\"\\nFirst 5 rows of preprocessed data:\")\n",
    "    display(df_processed.head())\n",
    "    \n",
    "    print(\"\\nChecking for missing values after preprocessing:\")\n",
    "    print(df_processed.isnull().sum().sum()) # Should be 0\n",
    "    \n",
    "    print(\"\\nData types after preprocessing:\")\n",
    "    df_processed.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Visualization (on Processed Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distributions of key processed features\n",
    "if 'df_processed' in locals():\n",
    "    plot_cols = ['ESG_Overall', 'ProfitMargin', 'MarketCap', 'Revenue', 'Industry', 'Region']\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i, col in enumerate(plot_cols):\n",
    "        plt.subplot(2, 3, i + 1)\n",
    "        sns.histplot(df_processed[col], kde=True)\n",
    "        plt.title(f'Processed Distribution of {col}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap for processed numerical columns\n",
    "if 'df_processed' in locals():\n",
    "    plot_correlation_matrix(df_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preparation for Machine Learning\n",
    "\n",
    "We'll define features (X) and targets (y) for our supervised learning tasks.\n",
    "\n",
    "**Tasks:**\n",
    "1.  **Regression:** Predict `ProfitMargin`.\n",
    "2.  **Classification:** Predict whether `ESG_Overall` score is 'High' (above median) or 'Low' (below or equal to median)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df_processed' in locals():\n",
    "    # --- Regression Task --- \n",
    "    target_reg = 'ProfitMargin'\n",
    "    # Use all other columns as features, except potential identifiers if they were kept\n",
    "    features_reg = df_processed.drop(columns=[target_reg]).columns.tolist()\n",
    "    \n",
    "    X_reg = df_processed[features_reg]\n",
    "    y_reg = df_processed[target_reg]\n",
    "    \n",
    "    # Train-test split for regression\n",
    "    X_reg_train, X_reg_test, y_reg_train, y_reg_test = train_test_split(\n",
    "        X_reg, y_reg, test_size=0.2, random_state=42\n",
    "    )\n",
    "    print(f\"Regression - Features shape: {X_reg.shape}, Target shape: {y_reg.shape}\")\n",
    "    print(f\"Train shapes: {X_reg_train.shape}, {y_reg_train.shape}\")\n",
    "    print(f\"Test shapes: {X_reg_test.shape}, {y_reg_test.shape}\")\n",
    "\n",
    "    # --- Classification Task --- \n",
    "    # Create a binary target based on the median ESG_Overall score\n",
    "    # Note: We use the *original* non-scaled ESG_Overall to determine the median for interpretability\n",
    "    if 'ESG_Overall' in df_original.columns:\n",
    "        median_esg = df_original['ESG_Overall'].median()\n",
    "        df_processed['ESG_Category'] = (df_processed['ESG_Overall'] > df_processed['ESG_Overall'].median()).astype(int) # Use median of scaled data for split\n",
    "        # Alternatively, use original median on scaled data: df_processed['ESG_Category'] = (df_original['ESG_Overall'] > median_esg).astype(int)\n",
    "        \n",
    "        target_clf = 'ESG_Category'\n",
    "        # Use all columns except the target and the original ESG score it's derived from\n",
    "        features_clf = df_processed.drop(columns=[target_clf, 'ESG_Overall']).columns.tolist()\n",
    "        \n",
    "        X_clf = df_processed[features_clf]\n",
    "        y_clf = df_processed[target_clf]\n",
    "        \n",
    "        # Train-test split for classification\n",
    "        X_clf_train, X_clf_test, y_clf_train, y_clf_test = train_test_split(\n",
    "            X_clf, y_clf, test_size=0.2, random_state=42, stratify=y_clf # Stratify for classification\n",
    "        )\n",
    "        print(f\"\\nClassification - Features shape: {X_clf.shape}, Target shape: {y_clf.shape}\")\n",
    "        print(f\"Train shapes: {X_clf_train.shape}, {y_clf_train.shape}\")\n",
    "        print(f\"Test shapes: {X_clf_test.shape}, {y_clf_test.shape}\")\n",
    "        print(f\"ESG Category distribution (0=Low, 1=High):\\n{df_processed['ESG_Category'].value_counts(normalize=True)}\")\n",
    "    else:\n",
    "        print(\"\\nWarning: 'ESG_Overall' column not found in original data for classification task setup.\")\n",
    "        X_clf_train, X_clf_test, y_clf_train, y_clf_test = [None]*4\n",
    "\n",
    "    # --- Data for Unsupervised Learning --- \n",
    "    # Typically use all relevant features (excluding target variables if any)\n",
    "    # For clustering/PCA, we might use a subset or all processed features\n",
    "    X_unsupervised = df_processed[features_reg] # Using regression features as an example\n",
    "    print(f\"\\nUnsupervised Learning - Data shape: {X_unsupervised.shape}\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nDataFrame df_processed not found. Skipping data preparation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Supervised Learning\n",
    "\n",
    "We will now apply the implemented supervised learning algorithms to the prepared datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Regression Task (Predicting ProfitMargin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.1 Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'X_reg_train' in locals() and X_reg_train is not None:\n",
    "    # Using Normal Equation (default)\n",
    "    lr_normal = LinearRegression(method='normal_equation')\n",
    "    lr_normal.fit(X_reg_train, y_reg_train)\n",
    "    y_reg_pred_normal = lr_normal.predict(X_reg_test)\n",
    "    mse_normal = mean_squared_error(y_reg_test, y_reg_pred_normal)\n",
    "    r2_normal = r2_score(y_reg_test, y_reg_pred_normal)\n",
    "    print(\"--- Linear Regression (Normal Equation) ---\")\n",
    "    print(f\"Mean Squared Error: {mse_normal:.4f}\")\n",
    "    print(f\"R^2 Score: {r2_normal:.4f}\")\n",
    "\n",
    "    # Using Gradient Descent\n",
    "    lr_gd = LinearRegression(method='gradient_descent', learning_rate=0.01, n_iterations=1000)\n",
    "    lr_gd.fit(X_reg_train.values, y_reg_train.values) # .values might be needed if fit expects numpy\n",
    "    y_reg_pred_gd = lr_gd.predict(X_reg_test.values)\n",
    "    mse_gd = mean_squared_error(y_reg_test, y_reg_pred_gd)\n",
    "    r2_gd = r2_score(y_reg_test, y_reg_pred_gd)\n",
    "    print(\"\\n--- Linear Regression (Gradient Descent) ---\")\n",
    "    print(f\"Mean Squared Error: {mse_gd:.4f}\")\n",
    "    print(f\"R^2 Score: {r2_gd:.4f}\")\n",
    "    \n",
    "    # Store results for comparison\n",
    "    regression_results = {'Linear Regression (Normal Eq.)': {'MSE': mse_normal, 'R2': r2_normal},\n",
    "                         'Linear Regression (GD)': {'MSE': mse_gd, 'R2': r2_gd}}\n",
    "    \n",
    "    # Visualization (Actual vs Predicted for Normal Equation)\n",
    "    plot_regression_results(y_reg_test, y_reg_pred_normal, 'Linear Regression (Normal Eq.)')\n",
    "else:\n",
    "    print(\"Regression data not prepared. Skipping Linear Regression.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.2 Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'X_reg_train' in locals() and X_reg_train is not None:\n",
    "    dt_reg = DecisionTreeRegressor(max_depth=10, min_samples_split=10, random_state=42)\n",
    "    dt_reg.fit(X_reg_train, y_reg_train)\n",
    "    y_reg_pred_dt = dt_reg.predict(X_reg_test)\n",
    "    mse_dt = mean_squared_error(y_reg_test, y_reg_pred_dt)\n",
    "    r2_dt = r2_score(y_reg_test, y_reg_pred_dt)\n",
    "    print(\"--- Decision Tree Regressor ---\")\n",
    "    print(f\"Mean Squared Error: {mse_dt:.4f}\")\n",
    "    print(f\"R^2 Score: {r2_dt:.4f}\")\n",
    "    \n",
    "    regression_results['Decision Tree Regressor'] = {'MSE': mse_dt, 'R2': r2_dt}\n",
    "    plot_regression_results(y_reg_test, y_reg_pred_dt, 'Decision Tree Regressor')\n",
    "else:\n",
    "    print(\"Regression data not prepared. Skipping Decision Tree Regressor.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.3 K-Nearest Neighbors (KNN) Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'X_reg_train' in locals() and X_reg_train is not None:\n",
    "    knn_reg = KNNRegressor(n_neighbors=7, weights='distance') \n",
    "    knn_reg.fit(X_reg_train, y_reg_train)\n",
    "    y_reg_pred_knn = knn_reg.predict(X_reg_test)\n",
    "    mse_knn = mean_squared_error(y_reg_test, y_reg_pred_knn)\n",
    "    r2_knn = r2_score(y_reg_test, y_reg_pred_knn)\n",
    "    print(\"--- KNN Regressor ---\")\n",
    "    print(f\"Mean Squared Error: {mse_knn:.4f}\")\n",
    "    print(f\"R^2 Score: {r2_knn:.4f}\")\n",
    "\n",
    "    regression_results['KNN Regressor'] = {'MSE': mse_knn, 'R2': r2_knn}\n",
    "    plot_regression_results(y_reg_test, y_reg_pred_knn, 'KNN Regressor')\n",
    "else:\n",
    "    print(\"Regression data not prepared. Skipping KNN Regressor.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.4 Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'X_reg_train' in locals() and X_reg_train is not None:\n",
    "    rf_reg = RandomForestRegressor(n_estimators=100, max_depth=10, min_samples_split=10, random_state=42)\n",
    "    rf_reg.fit(X_reg_train, y_reg_train)\n",
    "    y_reg_pred_rf = rf_reg.predict(X_reg_test)\n",
    "    mse_rf = mean_squared_error(y_reg_test, y_reg_pred_rf)\n",
    "    r2_rf = r2_score(y_reg_test, y_reg_pred_rf)\n",
    "    print(\"--- Random Forest Regressor ---\")\n",
    "    print(f\"Mean Squared Error: {mse_rf:.4f}\")\n",
    "    print(f\"R^2 Score: {r2_rf:.4f}\")\n",
    "\n",
    "    regression_results['Random Forest Regressor'] = {'MSE': mse_rf, 'R2': r2_rf}\n",
    "    plot_regression_results(y_reg_test, y_reg_pred_rf, 'Random Forest Regressor')\n",
    "else:\n",
    "    print(\"Regression data not prepared. Skipping Random Forest Regressor.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.5 Neural Network (Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'X_reg_train' in locals() and X_reg_train is not None:\n",
    "    # For regression, NN output layer should have 1 neuron and linear activation (or no activation)\n",
    "    # Adjust the NN implementation or use appropriate loss (e.g., MSE)\n",
    "    # Assuming the current NN implementation is for classification, we might need modifications\n",
    "    # For demonstration, let's assume it can be adapted (or skip if not directly applicable)\n",
    "    # If adapting: Output layer size = 1, loss = MSE, no activation on output\n",
    "    \n",
    "    # NOTE: The provided NN class seems geared towards classification (sigmoid/softmax). \n",
    "    # Adapting it fully for regression is beyond copy-pasting. We'll skip direct application here.\n",
    "    print(\"Skipping Neural Network for regression as the provided class seems classification-focused.\")\n",
    "    # nn_reg = NeuralNetwork(hidden_layer_size=64, activation='relu', learning_rate=0.001, n_iterations=500, batch_size=64, random_state=42)\n",
    "    # # Need to adapt fit/predict/loss for regression if possible, or implement a separate RegressionNN\n",
    "    # try:\n",
    "    #     # Assuming adaptation for regression (e.g., linear output, MSE loss)\n",
    "    #     nn_reg.fit(X_reg_train.values, y_reg_train.values.reshape(-1, 1)) # Reshape y for potential NN structure\n",
    "    #     y_reg_pred_nn = nn_reg.predict(X_reg_test.values).flatten() # Flatten if predict returns column vector\n",
    "    #     mse_nn = mean_squared_error(y_reg_test, y_reg_pred_nn)\n",
    "    #     r2_nn = r2_score(y_reg_test, y_reg_pred_nn)\n",
    "    #     print(\"\\n--- Neural Network (Regression) ---\")\n",
    "    #     print(f\"Mean Squared Error: {mse_nn:.4f}\")\n",
    "    #     print(f\"R^2 Score: {r2_nn:.4f}\")\n",
    "    #     regression_results['Neural Network Regressor'] = {'MSE': mse_nn, 'R2': r2_nn}\n",
    "    #     plot_regression_results(y_reg_test, y_reg_pred_nn, 'Neural Network Regressor')\n",
    "    # except Exception as e:\n",
    "    #     print(f\"Could not run Neural Network for regression: {e}\")\n",
    "else:\n",
    "     print(\"Regression data not prepared. Skipping Neural Network Regressor.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.6 Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'X_reg_train' in locals() and X_reg_train is not None:\n",
    "    gb_reg = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "    gb_reg.fit(X_reg_train, y_reg_train)\n",
    "    y_reg_pred_gb = gb_reg.predict(X_reg_test)\n",
    "    mse_gb = mean_squared_error(y_reg_test, y_reg_pred_gb)\n",
    "    r2_gb = r2_score(y_reg_test, y_reg_pred_gb)\n",
    "    print(\"--- Gradient Boosting Regressor ---\")\n",
    "    print(f\"Mean Squared Error: {mse_gb:.4f}\")\n",
    "    print(f\"R^2 Score: {r2_gb:.4f}\")\n",
    "\n",
    "    regression_results['Gradient Boosting Regressor'] = {'MSE': mse_gb, 'R2': r2_gb}\n",
    "    plot_regression_results(y_reg_test, y_reg_pred_gb, 'Gradient Boosting Regressor')\n",
    "else:\n",
    "    print(\"Regression data not prepared. Skipping Gradient Boosting Regressor.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.7 Regression Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'regression_results' in locals() and regression_results:\n",
    "    plot_model_comparison(regression_results, 'Regression Model Comparison (Lower MSE is Better)')\n",
    "    plot_model_comparison(regression_results, 'Regression Model Comparison (Higher R2 is Better)', metric='R2', higher_is_better=True)\n",
    "else:\n",
    "    print(\"No regression results to compare.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Classification Task (Predicting High/Low ESG_Overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.1 Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Perceptron expects labels -1 and 1. Our target is 0 and 1.\n",
    "# We need to map y_clf_train and y_clf_test.\n",
    "if 'X_clf_train' in locals() and X_clf_train is not None:\n",
    "    y_clf_train_perceptron = np.where(y_clf_train == 0, -1, 1)\n",
    "    y_clf_test_perceptron = np.where(y_clf_test == 0, -1, 1)\n",
    "\n",
    "    perceptron = Perceptron(learning_rate=0.01, n_iterations=1000, random_state=42)\n",
    "    perceptron.fit(X_clf_train, y_clf_train_perceptron)\n",
    "    y_clf_pred_perceptron_mapped = perceptron.predict(X_clf_test)\n",
    "    \n",
    "    # Map predictions back to 0/1 for standard metrics\n",
    "    y_clf_pred_perceptron = np.where(y_clf_pred_perceptron_mapped == -1, 0, 1)\n",
    "    \n",
    "    acc_perceptron = accuracy_score(y_clf_test, y_clf_pred_perceptron)\n",
    "    f1_perceptron = f1_score(y_clf_test, y_clf_pred_perceptron)\n",
    "    print(\"--- Perceptron ---\")\n",
    "    print(f\"Accuracy: {acc_perceptron:.4f}\")\n",
    "    print(f\"F1 Score: {f1_perceptron:.4f}\")\n",
    "    print(\"Classification Report:\\n\", classification_report(y_clf_test, y_clf_pred_perceptron))\n",
    "\n",
    "    # Store results for comparison\n",
    "    classification_results = {'Perceptron': {'Accuracy': acc_perceptron, 'F1': f1_perceptron}}\n",
    "    \n",
    "    # Plot results (e.g., confusion matrix) - Need a function for this\n",
    "    plot_classification_results(y_clf_test, y_clf_pred_perceptron, 'Perceptron', perceptron.errors)\n",
    "else:\n",
    "    print(\"Classification data not prepared. Skipping Perceptron.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.2 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'X_clf_train' in locals() and X_clf_train is not None:\n",
    "    log_reg = LogisticRegression(learning_rate=0.1, n_iterations=1000, random_state=42)\n",
    "    # Logistic Regression implementation expects y in {0, 1}\n",
    "    log_reg.fit(X_clf_train.values, y_clf_train.values) # Use .values if needed\n",
    "    y_clf_pred_logreg = log_reg.predict(X_clf_test.values)\n",
    "    \n",
    "    acc_logreg = accuracy_score(y_clf_test, y_clf_pred_logreg)\n",
    "    f1_logreg = f1_score(y_clf_test, y_clf_pred_logreg)\n",
    "    print(\"--- Logistic Regression ---\")\n",
    "    print(f\"Accuracy: {acc_logreg:.4f}\")\n",
    "    print(f\"F1 Score: {f1_logreg:.4f}\")\n",
    "    print(\"Classification Report:\\n\", classification_report(y_clf_test, y_clf_pred_logreg))\n",
    "\n",
    "    classification_results['Logistic Regression'] = {'Accuracy': acc_logreg, 'F1': f1_logreg}\n",
    "    # Pass log_reg.costs if available and adaptable for plotting\n",
    "    plot_classification_results(y_clf_test, y_clf_pred_logreg, 'Logistic Regression', log_reg.costs if hasattr(log_reg, 'costs') else None)\n",
    "else:\n",
    "    print(\"Classification data not prepared. Skipping Logistic Regression.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.3 K-Nearest Neighbors (KNN) Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'X_clf_train' in locals() and X_clf_train is not None:\n",
    "    knn_clf = KNNClassifier(n_neighbors=7, weights='distance')\n",
    "    knn_clf.fit(X_clf_train, y_clf_train)\n",
    "    y_clf_pred_knn = knn_clf.predict(X_clf_test)\n",
    "    \n",
    "    acc_knn = accuracy_score(y_clf_test, y_clf_pred_knn)\n",
    "    f1_knn = f1_score(y_clf_test, y_clf_pred_knn)\n",
    "    print(\"--- KNN Classifier ---\")\n",
    "    print(f\"Accuracy: {acc_knn:.4f}\")\n",
    "    print(f\"F1 Score: {f1_knn:.4f}\")\n",
    "    print(\"Classification Report:\\n\", classification_report(y_clf_test, y_clf_pred_knn))\n",
    "\n",
    "    classification_results['KNN Classifier'] = {'Accuracy': acc_knn, 'F1': f1_knn}\n",
    "    plot_classification_results(y_clf_test, y_clf_pred_knn, 'KNN Classifier')\n",
    "else:\n",
    "    print(\"Classification data not prepared. Skipping KNN Classifier.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.4 Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'X_clf_train' in locals() and X_clf_train is not None:\n",
    "    dt_clf = DecisionTreeClassifier(max_depth=10, min_samples_split=10, criterion='gini', random_state=42)\n",
    "    dt_clf.fit(X_clf_train, y_clf_train)\n",
    "    y_clf_pred_dt = dt_clf.predict(X_clf_test)\n",
    "    \n",
    "    acc_dt = accuracy_score(y_clf_test, y_clf_pred_dt)\n",
    "    f1_dt = f1_score(y_clf_test, y_clf_pred_dt)\n",
    "    print(\"--- Decision Tree Classifier ---\")\n",
    "    print(f\"Accuracy: {acc_dt:.4f}\")\n",
    "    print(f\"F1 Score: {f1_dt:.4f}\")\n",
    "    print(\"Classification Report:\\n\", classification_report(y_clf_test, y_clf_pred_dt))\n",
    "\n",
    "    classification_results['Decision Tree Classifier'] = {'Accuracy': acc_dt, 'F1': f1_dt}\n",
    "    plot_classification_results(y_clf_test, y_clf_pred_dt, 'Decision Tree Classifier')\n",
    "else:\n",
    "    print(\"Classification data not prepared. Skipping Decision Tree Classifier.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.5 Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'X_clf_train' in locals() and X_clf_train is not None:\n",
    "    rf_clf = RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_split=10, random_state=42)\n",
    "    rf_clf.fit(X_clf_train, y_clf_train)\n",
    "    y_clf_pred_rf = rf_clf.predict(X_clf_test)\n",
    "    \n",
    "    acc_rf = accuracy_score(y_clf_test, y_clf_pred_rf)\n",
    "    f1_rf = f1_score(y_clf_test, y_clf_pred_rf)\n",
    "    print(\"--- Random Forest Classifier ---\")\n",
    "    print(f\"Accuracy: {acc_rf:.4f}\")\n",
    "    print(f\"F1 Score: {f1_rf:.4f}\")\n",
    "    print(\"Classification Report:\\n\", classification_report(y_clf_test, y_clf_pred_rf))\n",
    "\n",
    "    classification_results['Random Forest Classifier'] = {'Accuracy': acc_rf, 'F1': f1_rf}\n",
    "    plot_classification_results(y_clf_test, y_clf_pred_rf, 'Random Forest Classifier')\n",
    "else:\n",
    "    print(\"Classification data not prepared. Skipping Random Forest Classifier.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.6 Neural Network (Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'X_clf_train' in locals() and X_clf_train is not None:\n",
    "    # Assuming binary classification (0/1 target)\n",
    "    # Output layer size = 1 (for sigmoid) or 2 (for softmax/one-hot)\n",
    "    # Let's assume the NN implementation handles binary with sigmoid output\n",
    "    nn_clf = NeuralNetwork(hidden_layer_size=64, activation='relu', learning_rate=0.01, \n",
    "                           n_iterations=500, batch_size=64, random_state=42)\n",
    "    \n",
    "    # NN might expect y as a column vector\n",
    "    y_train_nn = y_clf_train.values.reshape(-1, 1)\n",
    "    \n",
    "    nn_clf.fit(X_clf_train.values, y_train_nn)\n",
    "    y_clf_pred_nn = nn_clf.predict(X_clf_test.values) # predict usually returns class labels\n",
    "    \n",
    "    acc_nn = accuracy_score(y_clf_test, y_clf_pred_nn)\n",
    "    f1_nn = f1_score(y_clf_test, y_clf_pred_nn)\n",
    "    print(\"--- Neural Network Classifier ---\")\n",
    "    print(f\"Accuracy: {acc_nn:.4f}\")\n",
    "    print(f\"F1 Score: {f1_nn:.4f}\")\n",
    "    print(\"Classification Report:\\n\", classification_report(y_clf_test, y_clf_pred_nn))\n",
    "\n",
    "    classification_results['Neural Network Classifier'] = {'Accuracy': acc_nn, 'F1': f1_nn}\n",
    "    # Pass nn_clf.losses if available and adaptable for plotting\n",
    "    plot_classification_results(y_clf_test, y_clf_pred_nn, 'Neural Network Classifier', nn_clf.losses if hasattr(nn_clf, 'losses') else None)\n",
    "else:\n",
    "    print(\"Classification data not prepared. Skipping Neural Network Classifier.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.7 AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'X_clf_train' in locals() and X_clf_train is not None:\n",
    "    # AdaBoost implementation might require specific base estimators (like Decision Stumps)\n",
    "    # Using the DecisionTreeClassifier from the library as base (depth=1 for stump)\n",
    "    stump = DecisionTreeClassifier(max_depth=1)\n",
    "    ada = AdaBoostClassifier(base_estimator=stump, n_estimators=50, learning_rate=1.0, random_state=42)\n",
    "    \n",
    "    # AdaBoost implementation might expect y in {0, 1} or {-1, 1}. Assuming {0, 1} based on code.\n",
    "    ada.fit(X_clf_train, y_clf_train)\n",
    "    y_clf_pred_ada = ada.predict(X_clf_test)\n",
    "    \n",
    "    acc_ada = accuracy_score(y_clf_test, y_clf_pred_ada)\n",
    "    f1_ada = f1_score(y_clf_test, y_clf_pred_ada)\n",
    "    print(\"--- AdaBoost Classifier ---\")\n",
    "    print(f\"Accuracy: {acc_ada:.4f}\")\n",
    "    print(f\"F1 Score: {f1_ada:.4f}\")\n",
    "    print(\"Classification Report:\\n\", classification_report(y_clf_test, y_clf_pred_ada))\n",
    "\n",
    "    classification_results['AdaBoost Classifier'] = {'Accuracy': acc_ada, 'F1': f1_ada}\n",
    "    plot_classification_results(y_clf_test, y_clf_pred_ada, 'AdaBoost Classifier')\n",
    "else:\n",
    "    print(\"Classification data not prepared. Skipping AdaBoost Classifier.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.8 Classification Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'classification_results' in locals() and classification_results:\n",
    "    plot_model_comparison(classification_results, 'Classification Model Comparison (Higher Accuracy is Better)', metric='Accuracy', higher_is_better=True)\n",
    "    plot_model_comparison(classification_results, 'Classification Model Comparison (Higher F1 is Better)', metric='F1', higher_is_better=True)\n",
    "else:\n",
    "    print(\"No classification results to compare.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Unsupervised Learning\n",
    "\n",
    "We'll apply unsupervised algorithms for dimensionality reduction and clustering using the processed features (`X_unsupervised`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'X_unsupervised' in locals():\n",
    "    # Fit PCA to retain 95% of variance\n",
    "    pca = PCA(n_components=0.95)\n",
    "    X_pca = pca.fit_transform(X_unsupervised)\n",
    "    \n",
    "    print(\"--- Principal Component Analysis (PCA) ---\")\n",
    "    print(f\"Original number of features: {X_unsupervised.shape[1]}\")\n",
    "    print(f\"Number of components selected by PCA (to retain 95% variance): {pca.n_components_}\")\n",
    "    print(f\"Shape of transformed data: {X_pca.shape}\")\n",
    "    print(f\"Explained variance ratio per component: \\n{pca.explained_variance_ratio_}\")\n",
    "    print(f\"Cumulative explained variance: \\n{np.cumsum(pca.explained_variance_ratio_)}\")\n",
    "    \n",
    "    # Plot explained variance\n",
    "    plot_pca_results(pca)\n",
    "    \n",
    "    # Visualize the first two principal components (optional: color by a category like Industry)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    # Use original categorical data for coloring if available and makes sense\n",
    "    if 'Industry' in df_original.columns:\n",
    "         unique_industries = df_original['Industry'].unique()\n",
    "         colors = plt.cm.get_cmap('viridis', len(unique_industries))\n",
    "         industry_map = {industry: i for i, industry in enumerate(unique_industries)}\n",
    "         scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=df_original['Industry'].map(industry_map), cmap=colors, alpha=0.6)\n",
    "         plt.colorbar(scatter, label='Industry (Encoded)') # Adjust label if needed\n",
    "    else:\n",
    "         plt.scatter(X_pca[:, 0], X_pca[:, 1], alpha=0.6)\n",
    "\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.title('PCA: Data projected onto first two components')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"Unsupervised data not prepared. Skipping PCA.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'X_pca' in locals(): # Use PCA-transformed data for easier visualization/clustering\n",
    "    n_clusters_kmeans = 5 # Example number of clusters\n",
    "    kmeans = KMeans(n_clusters=n_clusters_kmeans, random_state=42)\n",
    "    kmeans.fit(X_pca) # Fit on PCA data (first few components)\n",
    "    kmeans_labels = kmeans.labels_\n",
    "    kmeans_silhouette = silhouette_score(X_pca, kmeans_labels)\n",
    "\n",
    "    print(\"--- K-Means Clustering ---\")\n",
    "    print(f\"Number of clusters: {n_clusters_kmeans}\")\n",
    "    print(f\"Inertia (Sum of squared distances): {kmeans.inertia_:.2f}\")\n",
    "    print(f\"Silhouette Score: {kmeans_silhouette:.4f}\")\n",
    "    \n",
    "    # Plot K-Means clusters using the first two PCA components\n",
    "    plot_clusters(X_pca, kmeans_labels, kmeans.centroids_, 'K-Means Clustering Results (on PCA data)')\n",
    "else:\n",
    "     print(\"PCA data not available. Skipping K-Means.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 DBSCAN Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'X_pca' in locals():\n",
    "    # DBSCAN parameters often require tuning. Using example values.\n",
    "    # We'll use the implementation from the library for DBSCAN as it's more complex.\n",
    "    dbscan = DBSCAN(eps=0.5, min_samples=5) \n",
    "    dbscan.fit(X_pca) # Fit on PCA data\n",
    "    dbscan_labels = dbscan.labels_\n",
    "    n_clusters_dbscan = len(set(dbscan_labels)) - (1 if -1 in dbscan_labels else 0)\n",
    "    n_noise = list(dbscan_labels).count(-1)\n",
    "    \n",
    "    print(\"--- DBSCAN Clustering ---\")\n",
    "    print(f\"Estimated number of clusters: {n_clusters_dbscan}\")\n",
    "    print(f\"Estimated number of noise points: {n_noise}\")\n",
    "    \n",
    "    # Calculate silhouette score only if more than 1 cluster is found (and not all points are noise)\n",
    "    if n_clusters_dbscan > 1:\n",
    "        dbscan_silhouette = silhouette_score(X_pca, dbscan_labels)\n",
    "        print(f\"Silhouette Score: {dbscan_silhouette:.4f}\")\n",
    "    else:\n",
    "        dbscan_silhouette = -1 # Or some indicator that it couldn't be calculated\n",
    "        print(\"Silhouette Score cannot be calculated (less than 2 clusters found).\")\n",
    "        \n",
    "    # Plot DBSCAN clusters\n",
    "    plot_clusters(X_pca, dbscan_labels, None, 'DBSCAN Clustering Results (on PCA data)') # No centroids for DBSCAN\n",
    "\n",
    "else:\n",
    "    print(\"PCA data not available. Skipping DBSCAN.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Clustering Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare K-Means and DBSCAN using Silhouette Score\n",
    "if 'kmeans_silhouette' in locals() and 'dbscan_silhouette' in locals():\n",
    "    clustering_comparison = {\n",
    "        'K-Means': {'Silhouette': kmeans_silhouette},\n",
    "        'DBSCAN': {'Silhouette': dbscan_silhouette if n_clusters_dbscan > 1 else np.nan} # Use NaN if score wasn't calculated\n",
    "    }\n",
    "    plot_model_comparison(clustering_comparison, 'Clustering Model Comparison (Higher Silhouette is Better)', \n",
    "                          metric='Silhouette', higher_is_better=True)\n",
    "else:\n",
    "    print(\"Clustering results not available for comparison.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Singular Value Decomposition (SVD) for Compression (Demonstration)\n",
    "\n",
    "Since the ESG dataset isn't image data, we'll demonstrate SVD on a sample matrix derived from the data (e.g., the correlation matrix or a subset of numerical features). The primary use case (image compression) requires image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'X_unsupervised' in locals():\n",
    "    print(\"--- Singular Value Decomposition (SVD) Demonstration ---\")\n",
    "    # Example: Apply SVD to a subset of the data (e.g., first 100 samples, first 10 features)\n",
    "    X_subset = X_unsupervised.iloc[:100, :10].values\n",
    "    print(f\"Applying SVD to a subset matrix of shape: {X_subset.shape}\")\n",
    "    \n",
    "    svd_comp = SVDCompression(n_components=None) # Keep all components initially\n",
    "    svd_comp.fit(X_subset) # Fit SVD\n",
    "    \n",
    "    # Plot explained variance ratio\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(np.cumsum(svd_comp.explained_variance_ratio_))\n",
    "    plt.xlabel('Number of Components')\n",
    "    plt.ylabel('Cumulative Explained Variance Ratio')\n",
    "    plt.title('SVD: Explained Variance by Number of Components')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Reconstruct using a smaller number of components (e.g., 5)\n",
    "    n_recon_components = 5\n",
    "    X_reconstructed = svd_comp.transform(n_components=n_recon_components)\n",
    "    reconstruction_error = np.linalg.norm(X_subset - X_reconstructed) / np.linalg.norm(X_subset)\n",
    "    print(f\"\\nReconstructing using {n_recon_components} components.\")\n",
    "    print(f\"Shape of reconstructed data: {X_reconstructed.shape}\")\n",
    "    print(f\"Relative Reconstruction Error: {reconstruction_error:.4f}\")\n",
    "    \n",
    "    # Note: Visualizing the reconstruction isn't meaningful here as it's not image data.\n",
    "    # For actual image compression, you would load an image, fit SVD, \n",
    "    # transform with fewer components, and display the reconstructed image.\n",
    "\n",
    "else:\n",
    "    print(\"Unsupervised data not available. Skipping SVD demonstration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusion\n",
    "\n",
    "This notebook demonstrated the application of various supervised and unsupervised learning algorithms on the ESG and Financial Performance dataset. \n",
    "\n",
    "**Key Steps:**\n",
    "* Data was loaded, explored, and preprocessed (handling missing values, encoding, scaling).\n",
    "* **Supervised Learning:**\n",
    "    * Regression models (Linear Regression, Decision Tree, KNN, Random Forest, Gradient Boosting) were trained to predict `ProfitMargin`. Performance varied, with ensemble methods (Random Forest, Gradient Boosting) often showing better R2 scores, indicating a better fit to the data than simpler models, though potentially overfitting if not tuned.\n",
    "    * Classification models (Perceptron, Logistic Regression, KNN, Decision Tree, Random Forest, AdaBoost, Neural Network) were trained to predict a derived `ESG_Category`. Again, ensemble methods and KNN generally performed well in terms of Accuracy and F1-score, suggesting complex relationships influence ESG standing. The simple Perceptron likely struggled with non-linearly separable data.\n",
    "* **Unsupervised Learning:**\n",
    "    * PCA successfully reduced the dimensionality while retaining a significant portion of the variance, enabling 2D visualization.\n",
    "    * K-Means and DBSCAN were applied to the PCA-reduced data, identifying potential clusters of companies. K-Means forced data into k clusters, while DBSCAN identified density-based clusters and marked some points as noise, which might be more realistic for this type of data. Silhouette scores provided a quantitative comparison, but visual inspection of clusters is also important.\n",
    "    * SVD was demonstrated on a matrix subset, showing how variance is captured by singular components, illustrating its potential for dimensionality reduction or (in its primary application) image compression.\n",
    "\n",
    "**Overall:** The analysis showcased the implementation and comparative performance of fundamental machine learning algorithms. The results suggest that ESG scores and financial metrics have complex interdependencies that are better captured by non-linear or ensemble models. Further work could involve more rigorous hyperparameter tuning, feature engineering, and exploring different classification/regression targets within the dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}